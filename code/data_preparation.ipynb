{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64eb0b26-5f3b-468c-9467-37398ff5227f",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook details the initial steps of preparing the [Vehicles.csv](https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data) dataset for analysis. It includes data loading, understanding, and cleaning processes to ensure the data is in a format for further analysis. Key tasks involve handling missing values, encoding categorical variables, normalizing numerical features, and addressing any data quality issues.\n",
    "\n",
    "By the end of this notebook, the dataset will be transformed into a refined version ready for exploratory data anlanlysis and model development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eabcb13-2b92-44fa-b05e-a7b71ebdfb39",
   "metadata": {},
   "source": [
    "### Loading Tools and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c04dc-3b86-4675-99d4-08b2be8740ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "\n",
    "df = pd.read_csv('../data/vehicles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef21d31-7337-4259-80cc-d5d3c94d4438",
   "metadata": {},
   "source": [
    "## Understanding The Data\n",
    "- Dataframe `shape`\n",
    "- `info`\n",
    "- `head` and `tail`\n",
    "- `describe`\n",
    "- `unique` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc4a455-10c8-472b-b46f-9026c6b3c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd05cc-04be-4d83-b9c5-a4b2f2a80406",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd07606-51d1-4901-a99f-799542eb14b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ce360b-9add-47f0-b5ed-f2086ae65b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4bbc14-0225-4118-beea-f5c217f96100",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_check = df.drop(['url', 'region', 'region_url', 'image_url', 'description'], axis=1).copy()\n",
    "for column, rows in unique_check.items():\n",
    "    print('----------')\n",
    "    print(f'{column} --- {df[column].unique()} --- {df[column].dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd32ea-a2b9-4fe0-a766-f46eb7dbd13b",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "- Dropping irrelevant columns and rows\n",
    "- Identifying duplicated columns / incorrect datatypes\n",
    "- Impute `NaN`\n",
    "- Renaming columns\n",
    "- Feature creation or addressing any concerns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7dcc7f-8c49-48bb-9c4e-2f2d06528e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column, row in df.items():\n",
    "    print(f'{column} - {round((df[column].isna().sum() / len(df)) * 100,2)}%')\n",
    "print('--------')\n",
    "print(f'Shape: {df.shape}')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e41525-1dee-46db-bba3-8035d8e534c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "    # 'id', 'url', 'region', 'region_url', 'VIN', 'size', \n",
    "    # 'county', 'image_url', 'description', 'posting_date',\n",
    "    'price', 'year', 'manufacturer', 'model', 'condition', 'cylinders', 'fuel', \n",
    "    'odometer', 'title_status', 'transmission', 'drive', 'type', 'paint_color',\n",
    "    'state', 'lat', 'long']].copy()\n",
    "\n",
    "assert len(df.columns) == 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f18b8-fc77-495f-9769-5692d85a2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical = ['year','odometer','lat','long']\n",
    "# nominal = ['manufacturer','model','fuel','transmission','type','paint_color','state']\n",
    "# ordinal = ['condition','cylinders','title_status','drive']\n",
    "\n",
    "# def impute_nans(df, column):\n",
    "#     df_notna = df[df[column].notnull()]\n",
    "#     df_isna = df[df[column].isna()]\n",
    "\n",
    "#     print(f'processing column: {column}')\n",
    "\n",
    "#     X_train = df_notna.drop(column, axis=1)\n",
    "#     y_train = df_notna[column]\n",
    "#     X_test = df_isna.drop(column, axis=1)\n",
    "\n",
    "#     numerical_features = [feature for feature in numerical if feature != column]\n",
    "#     nominal_features = [feature for feature in nominal if feature != column]\n",
    "#     ordinal_features = [feature for feature in ordinal if feature != column]\n",
    "\n",
    "#     impute_preprocessor = ColumnTransformer(\n",
    "#         transformers = [\n",
    "#             ('numerical', StandardScaler(), numerical_features),\n",
    "#             ('nominal', OneHotEncoder(sparse_output=False), nominal_features),\n",
    "#             ('ordinal', OrdinalEncoder(), ordinal_features)])\n",
    "\n",
    "#     impute_pipeline = Pipeline(\n",
    "#         steps = [\n",
    "#             ('preprocessor', impute_preprocessor),\n",
    "#             ('model', KNNImputer(n_neighbors=10))])\n",
    "\n",
    "#     print(\"X_train columns:\", X_train.columns)\n",
    "#     print(\"X_test columns:\", X_test.columns)\n",
    "#     print(\"y_train:\", y_train.name)\n",
    "\n",
    "#     impute_pipeline.fit(X_train, y_train)\n",
    "#     y_pred = impute_pipeline.predict(X_test)\n",
    "#     df.loc[df[column].isna(), column] = y_pred\n",
    "        \n",
    "#     return df\n",
    "\n",
    "# nan_columns = df.columns[df.isna().any()]\n",
    "# for column in nan_columns:\n",
    "#     df = impute_nans(df, column)\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea2175-2ea5-4b12-bcc8-b95aa66baed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = np.array_split(df, 100)\n",
    "for i, smaller_df in enumerate(dataframes):\n",
    "        smaller_df.to_csv(f'../data/vehicles_part_{i+1}.csv', index=False)\n",
    "\n",
    "file_path = '../data/vehicles.csv'\n",
    "        \n",
    "def process_dataframe(df):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[[\n",
    "        'price', 'year', 'manufacturer', 'model', 'condition', 'cylinders', 'fuel', \n",
    "        'odometer', 'title_status', 'transmission', 'drive', 'type', 'paint_color',\n",
    "        'state', 'lat', 'long']].copy()\n",
    "    \n",
    "    assert len(df.columns) == 16\n",
    "\n",
    "    numerical = ['year','odometer','lat','long']\n",
    "    nominal = ['manufacturer','model','fuel','transmission','type','paint_color','state']\n",
    "    ordinal = ['condition','cylinders','title_status','drive']\n",
    "\n",
    "    def impute_nans(df, column):\n",
    "        df_notna = df[df[column].notnull()]\n",
    "        df_isna = df[df[column].isna()]\n",
    "\n",
    "        print(f'processing column: {column}')\n",
    "\n",
    "        X_train = df_notna.drop(column, axis=1)\n",
    "        y_train = df_notna[column]\n",
    "        X_test = df_isna.drop(column, axis=1)\n",
    "\n",
    "        numerical_features = [feature for feature in numerical if feature != column]\n",
    "        nominal_features = [feature for feature in nominal if feature != column]\n",
    "        ordinal_features = [feature for feature in ordinal if feature != column]\n",
    "\n",
    "        impute_preprocessor = ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('numerical', StandardScaler(), numerical_features),\n",
    "                ('nominal', OneHotEncoder(sparse_output=False), nominal_features),\n",
    "                ('ordinal', OrdinalEncoder(), ordinal_features)])\n",
    "\n",
    "        impute_pipeline = Pipeline(\n",
    "            steps = [\n",
    "                ('preprocessor', impute_preprocessor),\n",
    "                ('model', IterativeImputer(estimator=RandomForestRegressor(), random_state=42))])\n",
    "        \n",
    "        print(\"X_train columns:\", X_train.columns)\n",
    "        print(\"X_test columns:\", X_test.columns)\n",
    "        print(\"y_train:\", y_train.name)\n",
    "\n",
    "        impute_pipeline.fit(X_train, y_train)\n",
    "        y_pred = impute_pipeline.predict(X_test)\n",
    "        df.loc[df[column].isna(), column] = y_pred\n",
    "\n",
    "        return df\n",
    "\n",
    "    nan_columns = df.columns[df.isna().any()]\n",
    "    for column in nan_columns:\n",
    "        df = impute_nans(df, column)\n",
    "\n",
    "    return df\n",
    "\n",
    "file_paths = [f'../data/vehicles_part_{i}.csv' for i in range(1, 101)]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    processed_df = process_dataframe(file_path)\n",
    "    processed_df.to_csv(file_path, index=False)  # Save to the same file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b5020-dd46-4b82-8348-f40e4f57bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical = ['DurationMonths', 'MonthlyCharges']\n",
    "# categorical = ['Contract']\n",
    "# estimator = LogisticRegression(random_state=42)\n",
    "\n",
    "# logreg_base = pipeline.fit(X_train, y_train)\n",
    "# logreg_ypred = logreg_base.predict(X_test)\n",
    "# logreg_accuracy = accuracy_score(y_test, logreg_ypred)\n",
    "# logreg_ypred_proba = logreg_base.predict_proba(X_test)\n",
    "# logreg_logloss = log_loss(y_test, logreg_ypred_proba)\n",
    "\n",
    "# print(logreg_accuracy)\n",
    "# print(logreg_logloss)\n",
    "# print(classification_report(y_test, logreg_ypred))\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers = [\n",
    "#         ('num', StandardScaler(), numerical),\n",
    "#         ('cat', OrdinalEncoder(), categorical)])\n",
    "\n",
    "# pipeline = Pipeline(\n",
    "#     steps = [\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('model', estimator)])\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "\n",
    "# df = df[df['year'].notnull()]\n",
    "# df = df[df['manufacturer'].notnull()]\n",
    "# df = df[df['model'].notnull()]\n",
    "# df = df[df['fuel'].notnull()]\n",
    "# df = df[df['odometer'].notnull()]\n",
    "# df = df[df['title_status'].notnull()]\n",
    "# df = df[df['transmission'].notnull()]\n",
    "# df = df[df['description'].notnull()]\n",
    "# df = df[df['lat'].notnull()]\n",
    "# df = df[df['long'].notnull()]\n",
    "# recent_30 = df['year'].max() - 30\n",
    "# df_30 = df[df['year'] >= recent_30]\n",
    "# df_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb1bd0-333d-4aaf-b58e-e8be8dc2d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print('Script executed successfully.')\n",
    "except:\n",
    "    print('Failed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
